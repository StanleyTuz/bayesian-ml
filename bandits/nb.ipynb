{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bandit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we're a business that sells one item and we fulfill every order from one of two allocations. Every time an order comes in, we have a decision to make: which store do we try to fulfill from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_true</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>y_obs</th>\n",
       "      <th>p_obs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.66</td>\n",
       "      <td>80</td>\n",
       "      <td>54</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.45</td>\n",
       "      <td>70</td>\n",
       "      <td>38</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           p_true  n_obs  y_obs     p_obs\n",
       "store_idx                                \n",
       "0            0.66     80     54  0.675000\n",
       "1            0.45     70     38  0.542857"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "tse = bandit.TwoStoresEnv()\n",
    "\n",
    "data_agg = pd.DataFrame.from_dict({\n",
    "    'store_idx': [0, 1],\n",
    "    'p_true': tse.ptfs[:,0],\n",
    "    'n_obs': [80, 70],\n",
    "},).set_index('store_idx')\n",
    "for store_idx in [0, 1]:\n",
    "    data_agg.loc[store_idx, 'y_obs'] = np.random.binomial(\n",
    "        n=data_agg.loc[store_idx, 'n_obs'],\n",
    "        p=data_agg.loc[store_idx, 'p_true'],\n",
    "        )\n",
    "data_agg['y_obs'] = data_agg['y_obs'].astype('int')\n",
    "data_agg['p_obs'] = data_agg['y_obs'] / data_agg['n_obs']\n",
    "data_agg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $p_{\\text{true}}$ is the latent probability of a location to fulfill an order successfully. In the standard supervised learning program (discriminative?), we typically have at least one of two related goals:\n",
    "1. Infer these probabilities from a labeled dataset;\n",
    "2. Make predictions based on these estimated inferred probabilities.\n",
    "\n",
    "Let's fit a standard supervised learning model to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "def bin_reg(X, y = None):\n",
    "    n_obs = X[:, 1] # number of observations\n",
    "\n",
    "    # define prior over location probabilities-to-fulfill\n",
    "    p_prior = dist.Uniform(low=0, high=1)\n",
    "\n",
    "    with pyro.plate('store', 2):\n",
    "        p = pyro.sample(\n",
    "            'p', p_prior,\n",
    "        )\n",
    "    \n",
    "    likelihood_dist = dist.Binomial(\n",
    "        total_count=n_obs, probs=p,\n",
    "    )\n",
    "    y_obs = pyro.sample(\n",
    "        'y_obs',\n",
    "        likelihood_dist,\n",
    "        obs=y,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 2500/2500 [00:12, 203.81it/s, step size=8.54e-01, acc. prob=0.932]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store 0: p_true = 0.660 ;  p_pred = 0.672\n",
      "Store 1: p_true = 0.450 ;  p_pred = 0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example: fitting a supervised learning model to the data\n",
    "\n",
    "import torch\n",
    "\n",
    "X = torch.tensor(data_agg.reset_index()[['store_idx','n_obs']].values)\n",
    "y = torch.tensor(data_agg['y_obs'].values)\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "from pyro.infer import NUTS, MCMC\n",
    "\n",
    "nuts_kernel = NUTS(bin_reg)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=2_000, warmup_steps=500)\n",
    "\n",
    "mcmc.run(X, y)\n",
    "\n",
    "# tse.ptfs[:,0]\n",
    "ptfs_pred = mcmc.get_samples()['p'].mean(axis=0)\n",
    "for i in range(2):\n",
    "    print(f\"Store {i}: p_true = {tse.ptfs[i,0]:.3f} ;  p_pred = {ptfs_pred[i]:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we fit any sort of ML model, we can use the model inferences/predictions in order to make decisions.\n",
    "\n",
    "For example, based on the above results, we would conclude that fulfillment location 0 has a higher baseline probability of being able to fulfill orders, and with this in mind, it would make sense to always allocate orders to this location (remember, this is a very simplified problem)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick decision theory\n",
    "\n",
    "We can formalize this decision-making process by assigning a cost to a failure and a success. Let's assume a successful fulfillment gives us nothing, but a failure costs us $5. We can write the decision loss/cost (higher is worse!) for deciding to allocate an order to a particular location as\n",
    "\n",
    "$$ L = 5 \\left(1-y\\right) $$\n",
    "\n",
    "where $y$ indicates the eventual result of the allocation. Since the eventual result of any allocation is of course uncertain, we should talk about the \"expected\" loss for this allocation decision:\n",
    "\n",
    "$$ \\mathbb{E}\\left[L\\right] = 5 \\left( 1- \\mathbb{E}\\left[y\\right]\\right) $$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our above inference, the expected result varies by store, and so we have a different expected loss per allocation for each store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_idx</th>\n",
       "      <th>ptfs_pred</th>\n",
       "      <th>expected_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.671967</td>\n",
       "      <td>1.640167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.541167</td>\n",
       "      <td>2.294164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_idx  ptfs_pred  expected_loss\n",
       "0          0   0.671967       1.640167\n",
       "1          1   0.541167       2.294164"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict({\n",
    "    'store_idx': [0, 1],\n",
    "    'ptfs_pred': ptfs_pred,\n",
    "    'expected_loss': 5*(1-ptfs_pred),\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus our intuition is borne out by combining our probabilistic belief of how the world works --- the PTFs inferred by our model --- with the decision loss function. For this simple problem, following this decision analysis would lead to us always allocating orders to location 0, since it has a low expected loss.\n",
    "\n",
    "(Technically we would probably sum this expected loss over the total expected number of orders at each store, but we aren't modeling that in this simple problem)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Approaches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = bandit.Agent()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ee19b82fd99a012bea4ec0e3f76be5c7a0cf5cc25d107856e87c55c22b4f3d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
