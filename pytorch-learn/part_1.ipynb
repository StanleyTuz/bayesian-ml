{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600453371877",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "> PyTorch is first and foremost a deep learning library.\n",
    "\n",
    "To do deep learning, need to \n",
    "* ingest data\n",
    "* define the model\n",
    "* train the model \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "PyTorch uses the core data structure `torch.tensor`, which is similar to the `numpy.ndarray`, and features accelerated mathematical operations. These can be used on the CPU or the GPU. Moving to GPU can be done in a few function calls (allegedly).\n",
    "\n",
    "PyTorch keeps track of operaations performed on `tensor`s, and this can be used to analytically compute derivatives with respect to any inputs. This greatly simplifies numerical optimizations. This opens PyTorch up to many scientific disciplines, not only machine learning (see physics, optimization, simulation, modeling).\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch version:  1.6.0\nCUDA available: False\n"
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"torch version:  {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "source": [
    "## Pretrained network example"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "dir(models)[0:5]\n",
    "\n",
    "alexnet = models.AlexNet()"
   ]
  },
  {
   "source": [
    "`alexnet` is an object which contains the AlexNet architecture."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "AlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)\n"
    }
   ],
   "source": [
    "print(alexnet)"
   ]
  },
  {
   "source": [
    "We can push data through this network, but we will get garbage since this is, of course, untrained. We can traain it or load models."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /Users/programming/.cache/torch/hub/checkpoints/resnet101-5d3b4d8f.pth\n100%|██████████| 170M/170M [00:04<00:00, 36.5MB/s]\n"
    }
   ],
   "source": [
    "resnet = models.resnet101(pretrained=True)"
   ]
  },
  {
   "source": [
    "The building blocks of a neural network are `torch.nn.Module`s. They are individual layers, or individual operations. We can print our model to see the `modules`, one per line:"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet;"
   ]
  },
  {
   "source": [
    "We can pass data to the model by calling the model like a function.\n",
    "\n",
    "First, we need to pre-process the inputs. For images, we need to standardize both their size and their intensity values.\n",
    "\n",
    "`torchvision.transforms` contains many basic preprocessing functions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img = Image.open(\"./data/man.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([3, 224, 224])"
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "img_t = preprocess(img)\n",
    "img_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_t = torch.unsqueeze(img_t, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([1, 3, 224, 224])"
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "batch_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put network into eval mode, to do inference\n",
    "resnet.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = resnet(batch_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/imagenet_classes.txt\") as fin:\n",
    "    labels = [line.strip() for line in fin.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'sweatshirt'"
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "_, index = torch.max(out,1)\n",
    "labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('sweatshirt', 99.03517150878906)"
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "percentage = torch.nn.functional.softmax(out, dim=1)\n",
    "percentage = percentage[0] * 100\n",
    "labels[index[0]], percentage[index[0]].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('sweatshirt', 99.03517150878906),\n ('lab coat, laboratory coat', 0.4077696204185486),\n ('ski mask', 0.06618981808423996),\n ('gar, garfish, garpike, billfish, Lepisosteus osseus', 0.044084902852773666),\n ('thunder snake, worm snake, Carphophis amoenus', 0.028538847342133522)]"
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "_, indices = torch.sort(out,descending=True)\n",
    "[(labels[idx], percentage[idx].item()) for idx in indices[0][:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}